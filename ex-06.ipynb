{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1910089377.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ---\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---\n",
    "  title: \"EX-06\"\n",
    "  author: \"Shreemithra Naveen\"\n",
    "  format:\n",
    "    html:\n",
    "      embed-resources: true\n",
    "  toc: true\n",
    "  jupyter: python3\n",
    "  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Preprocessing\n",
    "\n",
    "- Start by importing the necessary libraries and load the spam.csv dataset.\n",
    "\n",
    "- Preprocess the data by encoding categorical variables, defining features and target, and splitting the data into training and testing sets. Finally, apply PCA to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ual-laptop\\AppData\\Local\\Temp\\ipykernel_13844\\3888981261.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "spam = pd.read_csv(\"data/spam.csv\")\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = spam.select_dtypes(include = ['object', 'category']).columns.tolist()\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    spam[col] = label_encoders[col].fit_transform(spam[col])\n",
    "\n",
    "# Define features and target\n",
    "X = spam.drop('yesno', axis = 1)\n",
    "y = spam['yesno']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Reduce dimensionality\n",
    "pca = PCA(n_components = 2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Training and Decision Boundary Visualization\n",
    "\n",
    "- Train a Decision Tree classifier on the PCA-transformed training data.\n",
    "\n",
    "- Implement and use the `decisionplot` function (from the lecture) to visualize the decision boundary of your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train_pca, y_train)\n",
    "\n",
    "# Implement the decisionplot function (as provided in the lecture content)\n",
    "def decisionplot(model, X, y, resolution=216):\n",
    "    # Split the data into features (X) and the class variable (y)\n",
    "    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "# Add the decisionplot function here\n",
    "\n",
    "# Visualize decision boundary\n",
    "decisionplot(dtree, pd.DataFrame(X_train_pca, columns = ['PC1', 'PC2']), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Evaluation\n",
    "\n",
    "- Evaluate your model using accuracy, precision, recall, F1 score, and AUC-ROC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.81\n",
      "Recall: 0.81\n",
      "F1 Score: 0.81\n",
      "Macro-average ROC-AUC: 0.23\n",
      "ROC-AUC for the positive class: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Predictions\n",
    "predictions = dtree.predict(X_test_pca)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average = 'weighted')\n",
    "recall = recall_score(y_test, predictions, average = 'weighted')\n",
    "f1 = f1_score(y_test, predictions, average = 'weighted')\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# For AUC-ROC, binarize the output and calculate AUC-ROC for each class\n",
    "# Add the necessary code for AUC-ROC calculation here (refer to lecture content)\n",
    "# Binarize the output for multiclass\n",
    "#y_test_binarized = label_binarize(y_test, classes = np.unique(y_train))\n",
    "#n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "y_score = dtree.predict_proba(X_test_pca)\n",
    "positive_class_probabilities = y_score[:, 1]\n",
    "\n",
    "# Get the probability predictions for each class\n",
    "y_score = dtree.predict_proba(X_test_pca)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calculate macro-average ROC-AUC\n",
    "roc_auc_macro = np.mean(list(roc_auc.values()))\n",
    "print(f\"Macro-average ROC-AUC: {roc_auc_macro:.2f}\")\n",
    "\n",
    "# Calculate micro-average ROC-AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, positive_class_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"ROC-AUC for the positive class: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:\n",
    "- Implement the missing parts of the code: the decisionplot function and AUC-ROC calculation.\n",
    "Completed \n",
    "\n",
    "- Discuss the results among your peers. Consider the following:\n",
    "\n",
    "    - Which metric is most informative for this problem and why?\n",
    "    Ans. \n",
    "\n",
    "    - How does the decision boundary visualization help in understanding the modelâ€™s performance?\n",
    "\n",
    "    - Reflect on the impact of PCA on model performance and decision boundary.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
